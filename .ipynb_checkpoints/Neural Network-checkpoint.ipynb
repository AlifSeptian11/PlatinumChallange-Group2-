{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a285e2f-4091-43d0-ac11-efc7ea967de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af37542-3ca2-421f-8892-f7da730adc21",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c684f3-6e38-42cd-a857-0d376d289446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Label\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('DATA/train_preprocess.tsv.txt', sep='\\t', names=['Tweet','Label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c30d20-1f11-4ea5-8336-80ff6ad3abf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "positive    6416\n",
       "negative    3436\n",
       "neutral     1148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56990b8b-bd3f-4f91-a304-be86f2aaa6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data setelah menghapus duplikat:\n",
      "                                                   Tweet     Label\n",
      "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
      "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
      "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
      "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
      "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
      "...                                                  ...       ...\n",
      "10993  f - demokrat dorong upaya kemandirian energi n...   neutral\n",
      "10994                                        tidak bosan  positive\n",
      "10996  enak rasa masakan nya apalagi kepiting yang me...  positive\n",
      "10998  pagi pagi di tol pasteur sudah macet parah , b...  negative\n",
      "10999  meskipun sering belanja ke yogya di riau junct...  positive\n",
      "\n",
      "[10933 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Menghapus duplikat pada kolom \"tweet\"\n",
    "df = df.drop_duplicates(subset='Tweet')\n",
    "\n",
    "# Memeriksa data setelah menghapus duplikat\n",
    "print(\"\\nData setelah menghapus duplikat:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb156661-f98e-40bf-b18a-1a28f89c240e",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4a40b2c-6925-44f8-8d11-715ceaba4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(sent):\n",
    "    # Mengubah kata menjadi huruf kecil semua dengan menggunakan fungsi lower()\n",
    "    string = sent.lower()\n",
    "\n",
    "    # Menghapus emoticon dan tanda baca menggunakan \"RegEx\" dengan script di bawah\n",
    "    string = re.sub(r'(?:\\@|http?\\://|https?\\://|www)\\S+', '', string) #menghapus https dan http\n",
    "    string = re.sub('<.*?>', ' ', string) #mengganti karakter html dengan tanda petik\n",
    "    string = re.sub('[^0-9a-zA-Z]+', ' ', string) #menghilangkan semua karakter yang bukan huruf atau angka dan menggantinya dengan spasi.\n",
    "    string = re.sub('\\n',' ',string) #mengganti line baru dengan spasi\n",
    "    string = re.sub(r':', ' ', string) #menggantikan karakter : dengan spasi \n",
    "    string = re.sub('gue','saya', string) # Mengganti kata \"gue\" dengan kata \"saya\"\n",
    "    string = re.sub(r'\\b[a-zA-Z]\\b', ' ', string) #menghapus single char\n",
    "    string = ' '.join(string.split()) #memisahkan dan menggabungkan kata\n",
    "    string = string.strip() #menghilangkan whitespace di awal dan di akhir teks\n",
    "    string = re.sub(r'pic.twitter.com.[\\w]+', '', string) #menghapus link picture\n",
    "    string = re.sub(r'\\buser\\b',' ', string) #menghapus kata 'user'\n",
    "    string = re.sub(r'\\brt\\b',' ', string) #menghapus awalan rt\n",
    "    string = re.sub('RT',' ', string) #menghapus RT simbol\n",
    "    string = re.sub(r'‚Ä¶', '', string) #menghapus simbol tidak perlu\n",
    "\n",
    "    # Lematisasi menggunakan Sastrawi\n",
    "    stemmer_factory = StemmerFactory()\n",
    "    stemmer = stemmer_factory.create_stemmer()\n",
    "    string = stemmer.stem(string)\n",
    "\n",
    "    # Menghapus stop words menggunakan Sastrawi\n",
    "    stopword_factory = StopWordRemoverFactory()\n",
    "    stopword_remover = stopword_factory.create_stop_word_remover()\n",
    "    string = stopword_remover.remove(string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf3d9a0-9288-4756-ace0-f8397d5b2578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis di jalan sumatera bandung tem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>duh jadi mahasiswa jangan sombong dong kasih k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>f - demokrat dorong upaya kemandirian energi n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>demokrat dorong upaya kemandirian energi nasional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10994</th>\n",
       "      <td>tidak bosan</td>\n",
       "      <td>positive</td>\n",
       "      <td>tidak bosan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>positive</td>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah bik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>positive</td>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10933 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet     Label  \\\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2      lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "3      betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "...                                                  ...       ...   \n",
       "10993  f - demokrat dorong upaya kemandirian energi n...   neutral   \n",
       "10994                                        tidak bosan  positive   \n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...  positive   \n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...  negative   \n",
       "10999  meskipun sering belanja ke yogya di riau junct...  positive   \n",
       "\n",
       "                                             Tweet_Clean  \n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...  \n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...  \n",
       "2      lokasi strategis di jalan sumatera bandung tem...  \n",
       "3      betapa bahagia nya diri ini saat unboxing pake...  \n",
       "4      duh jadi mahasiswa jangan sombong dong kasih k...  \n",
       "...                                                  ...  \n",
       "10993  demokrat dorong upaya kemandirian energi nasional  \n",
       "10994                                        tidak bosan  \n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...  \n",
       "10998  pagi pagi di tol pasteur sudah macet parah bik...  \n",
       "10999  meskipun sering belanja ke yogya di riau junct...  \n",
       "\n",
       "[10933 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_Clean'] = df.Tweet.apply(cleansing)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd36fa2-a22a-4075-ba93-2765419e2856",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ad966-3d11-468d-94cd-f9103f67fbc9",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef72d685-83b6-4c2c-8964-b62f3336a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = df.Tweet_Clean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9935f3a-8b6a-4d84-9660-5c353e1f2e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction selesai\n"
     ]
    }
   ],
   "source": [
    "# Proses feature extraction\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "X = tfidf_vect.fit_transform(data_preprocessed)\n",
    "print(\"Feature extraction selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c059596-a23f-42b1-9e32-244cf8007568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        00  000  001   01  010  0111  011770465655617   02  021  022  ...  \\\n",
      "0      0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "1      0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "2      0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "3      0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "4      0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "...    ...  ...  ...  ...  ...   ...              ...  ...  ...  ...  ...   \n",
      "10928  0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "10929  0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "10930  0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "10931  0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "10932  0.0  0.0  0.0  0.0  0.0   0.0              0.0  0.0  0.0  0.0  ...   \n",
      "\n",
      "       zonpoliticon  zoo  zoom  zubir  zulfikri  zulkarnain  zup  zupa  zuppa  \\\n",
      "0               0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "1               0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "2               0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "3               0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "4               0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "...             ...  ...   ...    ...       ...         ...  ...   ...    ...   \n",
      "10928           0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "10929           0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "10930           0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "10931           0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "10932           0.0  0.0   0.0    0.0       0.0         0.0  0.0   0.0    0.0   \n",
      "\n",
      "       zwitsal  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "...        ...  \n",
      "10928      0.0  \n",
      "10929      0.0  \n",
      "10930      0.0  \n",
      "10931      0.0  \n",
      "10932      0.0  \n",
      "\n",
      "[10933 rows x 17237 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf_array = X.toarray()\n",
    "df_array = pd.DataFrame(data=tfidf_array, columns=tfidf_vect.get_feature_names_out())\n",
    "print(df_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd770d-23fc-4c0b-9c1c-3e1631eff4ce",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Dataset (Split Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8543ac57-5877-4386-b68e-d0ffa52ec681",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df.Label\n",
    "\n",
    "# split dataset menjadi 80% untuk train dan 20% untuk test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b51558b6-0d20-4dad-a6a5-2b767059c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8746, 17237)\n",
      "(2187, 17237)\n",
      "(8746,)\n",
      "(2187,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672c654-a825-4395-97ca-ef965dc51076",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5389d6-4750-44f7-8fbe-38653d5142bb",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed5f273-78c6-4c6a-81a0-410c6485e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai\n"
     ]
    }
   ],
   "source": [
    "# model training menggunakan neural network\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "747a63e5-9dab-4f65-99b3-0efd84fd6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7736eb-0cc6-4417-ba31-250a14809147",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d261f50-3b77-41e1-aa68-acef0c705bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78       669\n",
      "     neutral       0.85      0.67      0.75       232\n",
      "    positive       0.88      0.91      0.89      1286\n",
      "\n",
      "    accuracy                           0.84      2187\n",
      "   macro avg       0.84      0.79      0.81      2187\n",
      "weighted avg       0.84      0.84      0.84      2187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = model.predict(X_test)\n",
    "\n",
    "print(\"Testing selesai\")\n",
    "print(classification_report(y_test, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a655428-d76e-4aa8-9f09-6cbb156935d0",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "606b3dd9-34ca-4260-97a2-75775f427124",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Tweet_Clean\"]] #input feature\n",
    "Y = df[\"Label\"] #output feature\n",
    "\n",
    "# split dataset menjadi 80% untuk train dan 20% untuk test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc543eb8-7682-48e7-bf2e-d739810f25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation dengan split = 5\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "def cross_validation(k, X_train, model, name):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # iterate sebanyak k_cross validation\n",
    "    for iteration, data in enumerate(kf.split(X_train), start=1):\n",
    "        # mengambil data dan target train\n",
    "        data_train = X_train[data[0]]\n",
    "        tfidf_vect = TfidfVectorizer()\n",
    "        data_train = tfidf_vect.fit_transform(data_train)\n",
    "        target_train = y_train[data[0]]\n",
    "\n",
    "        # mengambil data dan target test\n",
    "        data_test = y_train[data[1]]\n",
    "        data_test = tfidf_vect.fit_transform(data_test)\n",
    "        target_test = y_train[data[1]]\n",
    "\n",
    "        # model training menggunakan data train\n",
    "        classifier = model\n",
    "        classifier.fit(data_train, target_train)\n",
    "\n",
    "        # prediksi data test\n",
    "        preds = classifier.predict(data_test)\n",
    "\n",
    "        # menghitung accuracy\n",
    "        accuracy = accuracy_score(target_test, preds)\n",
    "        precision = precision_score(target_test, preds)\n",
    "        recall = recall_score(target_test, preds)\n",
    "        f1 = f1_score(target_test, preds)\n",
    "\n",
    "        print(\"Training ke-\", iteration)\n",
    "        print(classification_report(target_test, preds))\n",
    "        print(\"=================================================================\")\n",
    "\n",
    "    result = {'algorithm': name,\n",
    "                'accuracy_per_iter': accuracies, 'accuracy_mean': mean(accuracies), 'accuracy_std': stdev(accuracies),\n",
    "                'recall_mean': mean(recalls),'precision_mean': mean(precisions), 'f1_mean': mean(f1_scores)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e525d7-6649-4c0e-8a75-8e76dd703750",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but MLPClassifier is expecting 13786 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLPClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeural Network\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m result\n",
      "Cell \u001b[1;32mIn[20], line 30\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(k, X_train, model, name)\u001b[0m\n\u001b[0;32m     27\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(data_train, target_train)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# prediksi data test\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# menghitung accuracy\u001b[39;00m\n\u001b[0;32m     33\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(target_test, preds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1160\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \n\u001b[0;32m   1149\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1164\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1164\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1167\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:207\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m--> 207\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Initialize first layer\u001b[39;00m\n\u001b[0;32m    210\u001b[0m activation \u001b[38;5;241m=\u001b[39m X\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 3 features, but MLPClassifier is expecting 13786 features as input."
     ]
    }
   ],
   "source": [
    "result = cross_validation(5, X_train, MLPClassifier(), \"Neural Network\")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
