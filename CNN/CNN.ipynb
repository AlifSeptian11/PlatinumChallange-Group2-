{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58eb260-ec12-4f62-9220-bfc5b8995556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Reza Fakhrurrozi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as sq\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5bee8-8eeb-4d54-aa90-2d20b82945a8",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef26380-85a1-4aaf-8940-32642ad712d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatra bandung temp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aduh jadi mahasiswa jangan sombong dong kasih ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>makanan beragam harga makanan di food stall ak...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pakai kartu kredit baca tidak untung malah rug...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tempat unik bagus buat foto makanan enak pegaw...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saya bersama keluarga baru saja menikmati peng...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bersyukur</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Label\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatra bandung temp...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  aduh jadi mahasiswa jangan sombong dong kasih ...  negative\n",
       "5  makanan beragam harga makanan di food stall ak...  positive\n",
       "6  pakai kartu kredit baca tidak untung malah rug...  negative\n",
       "7  tempat unik bagus buat foto makanan enak pegaw...  positive\n",
       "8  saya bersama keluarga baru saja menikmati peng...  positive\n",
       "9                                          bersyukur  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = sq.connect('C:/Users/Reza Fakhrurrozi/Documents/GitHub/PlatinumChallange-Group2-/database_pl.db', check_same_thread = False)\n",
    "q_data = 'SELECT * FROM data'\n",
    "df = pd.read_sql_query(q_data, db)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8b18b2-044f-491a-9fc1-72f5864bfa3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "positive    6383\n",
       "negative    3412\n",
       "neutral     1138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4a385-f490-4e19-a1b9-95f8ed842854",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62430a10-f7db-46ed-814a-6b5fd3b10348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(sent):\n",
    "    string = sent.lower()\n",
    "    string = re.sub(r'[^a-zA-Z0-9]', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fc603a-aafc-4f92-a45e-797b84ce740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatra bandung temp...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis di jalan sumatra bandung temp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aduh jadi mahasiswa jangan sombong dong kasih ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>aduh jadi mahasiswa jangan sombong dong kasih ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Label  \\\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2  lokasi strategis di jalan sumatra bandung temp...  positive   \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4  aduh jadi mahasiswa jangan sombong dong kasih ...  negative   \n",
       "\n",
       "                                         Tweet_Clean  \n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...  \n",
       "2  lokasi strategis di jalan sumatra bandung temp...  \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  \n",
       "4  aduh jadi mahasiswa jangan sombong dong kasih ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_Clean'] = df.Tweet.apply(cleansing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9da06-2f5a-49a8-9f00-5635c8aa8c51",
   "metadata": {},
   "source": [
    "# Feature Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a300045-4a9e-48bd-8698-812b60fb6633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "positive    6383\n",
      "negative    3412\n",
      "neutral     3412\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# memfilter data berdasarkan label\n",
    "df_positive = df[df['Label'] == 'positive']\n",
    "df_negative = df[df['Label'] == 'negative']\n",
    "df_neutral = df[df['Label'] == 'neutral']\n",
    "\n",
    "# menyeimbangkan label netral dengan label negatif\n",
    "df_neutral_over = df_neutral.sample(df_negative.shape[0], replace=True)\n",
    "\n",
    "#menggabungan semua data\n",
    "df = pd.concat([df_positive, df_negative, df_neutral_over])\n",
    "\n",
    "# mengecek kembali\n",
    "label_counts = df['Label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d34664-73c7-4baf-b5dd-b215e2fb4fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 6383, Negative: 3412, Neutral: 3412\n",
      "Total data: 13207\n",
      "Total labels: 13207\n"
     ]
    }
   ],
   "source": [
    "# Group data tweet\n",
    "positive_tweet = df.loc[df['Label']=='positive'].Tweet.tolist()\n",
    "negative_tweet = df.loc[df['Label']=='negative'].Tweet.tolist()\n",
    "neutral_tweet = df.loc[df['Label']=='neutral'].Tweet.tolist()\n",
    "\n",
    "# Group data label\n",
    "positive_label = df.loc[df['Label']=='positive'].Label.tolist()\n",
    "negative_label = df.loc[df['Label']=='negative'].Label.tolist()\n",
    "neutral_label = df.loc[df['Label']=='neutral'].Label.tolist()\n",
    "\n",
    "total_data = positive_tweet + negative_tweet + neutral_tweet\n",
    "labels = positive_label + neutral_label + negative_label\n",
    "\n",
    "print(\"Positive: %s, Negative: %s, Neutral: %s\" % (len(positive_tweet), len(negative_tweet), len(neutral_tweet)))\n",
    "print(\"Total data: %s\" % len(total_data))\n",
    "print(\"Total labels: %s\" % len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e4e2e-9f75-42f8-9575-e8a9ab1b2e48",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063b2573-3c69-4d48-9bf9-9494ef74c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pickle has been created!\n",
      "x_pad_sequences.pickle has been created!\n"
     ]
    }
   ],
   "source": [
    "max_features = 5000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ', lower=True)\n",
    "tokenizer.fit_on_texts(total_data)\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"tokenizer.pickle has been created!\")\n",
    "\n",
    "X = tokenizer.texts_to_sequences(total_data)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "maxlen = max(len(x) for x in X)\n",
    "\n",
    "X = pad_sequences(X)\n",
    "with open('x_pad_sequences.pickle', 'wb') as handle:\n",
    "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"x_pad_sequences.pickle has been created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3d5d7-0552-43c0-8764-c88b4f3aeafb",
   "metadata": {},
   "source": [
    "# Train-Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ea9519-2933-4b6a-88a6-ca99e7928e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labels.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(labels)\n",
    "Y = Y.values\n",
    "\n",
    "with open('y_labels.pickle', 'wb') as handle:\n",
    "    pickle.dump(Y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"y_labels.pickle has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a042d90b-26f2-432d-bb61-e42bdbda83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"C:/Users/Reza Fakhrurrozi/Documents/GitHub/PlatinumChallange-Group2-/CNN/x_pad_sequences.pickle\", 'rb')\n",
    "X = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(\"C:/Users/Reza Fakhrurrozi/Documents/GitHub/PlatinumChallange-Group2-/CNN/y_labels.pickle\", 'rb')\n",
    "Y = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fcb91-879e-47a9-b164-ecff7cdc99d5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e478b-aa25-414d-9870-184828c8ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be351f56-5432-4930-bc40-c8de8829c384",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90aafa6-ce43-46c2-893c-02a3eab510f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = predictions\n",
    "matrix_test = metrics.classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Testing selesai\")\n",
    "print(matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c1beb-0b38-49b2-a2ae-c3fae8ff685b",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af51a36-8fa5-485f-a11a-23142e690933",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "y = Y\n",
    "\n",
    "embed_dim = 200\n",
    "\n",
    "for iteration, data in enumerate(kf.split(X), start=1):\n",
    "    data_train   = X[data[0]]\n",
    "    target_train = y[data[0]]\n",
    "\n",
    "    data_test    = X[data[1]]\n",
    "    target_test  = y[data[1]]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_dim, input_length=maxlen))\n",
    "    model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "          \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0)\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1, callbacks=[es])\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    y_pred = predictions\n",
    "\n",
    "    accuracy = accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "    print(\"Training -\", iteration)\n",
    "    print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446a592-a470-4855-95b6-be4f19618c46",
   "metadata": {},
   "source": [
    "# Visualization & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616206ba-0b76-46c0-aa17-23cf685368f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "%matplotlib inline\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6169d-f88a-43c2-93eb-672b769d1a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menyimpan model\n",
    "\n",
    "model.save('model.h5')\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924733bf-e53d-4509-9fe9-a5c9f6caa91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Rasa syukur, cukup\"\"\"\n",
    "\n",
    "def cleansing(sent):\n",
    "    string = sent.lower()\n",
    "    string = re.sub(r'[^a-zA-Z0-9]', ' ', string)\n",
    "    return string\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "text = [cleansing(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model('model.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "hasil = sentiment[polarity]\n",
    "\n",
    "print(\"Text: \", text[0])\n",
    "print(\"Sentiment: \", hasil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
